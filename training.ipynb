{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from ultralytics import YOLO  # YOLOv8 library\n",
    "\n",
    "# Load YOLOv8 model for face detection\n",
    "face_detector = YOLO(\"face_yolov8s.pt\")\n",
    "print(\"YOLOv8 Face Detection Model loaded successfully!\")\n",
    "\n",
    "# Step 1: Define paths\n",
    "dataset_path = \"dataset\"\n",
    "classes = [\"Aahad\", \"Ali\", \"Baba\", \"Bisma\", \"Damysha\", \"Daud\", \"Fahad\", \"Gujjar\", \"Sameed\", \"Saqib\", \"Unaiza\", \"Zunaira\"]\n",
    "\n",
    "# Step 2: Detect and crop face\n",
    "def detect_and_crop_face(image_path):\n",
    "    \"\"\"\n",
    "    Detects and crops the face region from an image using YOLOv8 face detection.\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "    Returns:\n",
    "        PIL.Image: Cropped face image or None if no face is detected.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    results = face_detector.predict(source=np.array(image), conf=0.5, iou=0.45, save=False, save_crop=False, device=\"cpu\")\n",
    "    \n",
    "    # Process detection results\n",
    "    if len(results[0].boxes) > 0:\n",
    "        # Take the first detected face (highest confidence)\n",
    "        box = results[0].boxes[0].xyxy[0].cpu().numpy()\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cropped_face = image.crop((x1, y1, x2, y2))\n",
    "        return cropped_face.resize((160, 160))  # Resize for FaceNet\n",
    "    else:\n",
    "        return None  # No face detected\n",
    "\n",
    "# Step 3: Augmentation setup\n",
    "def augment_images(image, output_dir, augmentations=5):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    image_array = np.expand_dims(np.array(image), axis=0)\n",
    "    augmented_images = datagen.flow(image_array, batch_size=1)\n",
    "    for i in range(augmentations):\n",
    "        aug_image = next(augmented_images)[0]\n",
    "        Image.fromarray(aug_image.astype('uint8')).save(os.path.join(output_dir, f\"aug_{i}.jpg\"))\n",
    "\n",
    "# Step 4: Prepare the dataset with face detection and augmentation\n",
    "def prepare_augmented_dataset(dataset_path, augmentations=5):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for label, cls in enumerate(classes):\n",
    "        class_path = os.path.join(dataset_path, cls)\n",
    "        aug_output_path = os.path.join(dataset_path, f\"{cls}_augmented\")\n",
    "        os.makedirs(aug_output_path, exist_ok=True)\n",
    "\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            cropped_face = detect_and_crop_face(img_path)\n",
    "            if cropped_face is not None:\n",
    "                # Original face image\n",
    "                data.append(np.array(cropped_face))\n",
    "                labels.append(label)\n",
    "                # Augmented face images\n",
    "                augment_images(cropped_face, aug_output_path, augmentations)\n",
    "                for aug_img_name in os.listdir(aug_output_path):\n",
    "                    aug_img_path = os.path.join(aug_output_path, aug_img_name)\n",
    "                    data.append(np.array(Image.open(aug_img_path)))\n",
    "                    labels.append(label)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "print(\"Detecting faces, augmenting images, and preparing dataset...\")\n",
    "X, y = prepare_augmented_dataset(dataset_path, augmentations=5)\n",
    "print(f\"Dataset prepared with {len(X)} images.\")\n",
    "\n",
    "# Step 5: Generate embeddings using FaceNet\n",
    "print(\"Generating embeddings...\")\n",
    "facenet_model = FaceNet()\n",
    "embeddings = np.array([facenet_model.embeddings([img])[0] for img in X])\n",
    "print(\"Embeddings generated successfully!\")\n",
    "\n",
    "# Step 6: Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Train the SVM classifier\n",
    "print(\"Training SVM classifier...\")\n",
    "classifier = SVC(kernel='linear', probability=True)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(\"Classifier trained successfully!\")\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=classes))\n",
    "\n",
    "# Step 9: Print Accuracy in Percentage\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Step 10: Predict an input image\n",
    "import cv2\n",
    "\n",
    "def predict_image(image_path):\n",
    "    \"\"\"\n",
    "    Predicts whether the face in the input image is 'aahad' or 'sameed'.\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "    Returns:\n",
    "        str: Predicted class label.\n",
    "    \"\"\"\n",
    "    # Detect and crop the face\n",
    "    cropped_face = detect_and_crop_face(image_path)\n",
    "    if cropped_face is not None:\n",
    "        # Convert PIL image to NumPy array\n",
    "        cropped_face_array = np.array(cropped_face)\n",
    "        \n",
    "        # Resize image to FaceNet's expected input size (160x160)\n",
    "        cropped_face_resized = cv2.resize(cropped_face_array, (160, 160))\n",
    "        \n",
    "        # Generate embedding for the cropped face\n",
    "        embedding = facenet_model.embeddings([cropped_face_resized])[0].reshape(1, -1)\n",
    "        \n",
    "        # Predict using the trained SVM classifier\n",
    "        prediction = classifier.predict(embedding)\n",
    "        return classes[prediction[0]]\n",
    "    else:\n",
    "        return \"No face detected\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained classifier\n",
    "joblib.dump(classifier, 'classifier.pkl')\n",
    "print(\"Classifier saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=classes))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
